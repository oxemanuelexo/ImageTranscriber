# Image Transcriber ¬∑ GPT‚Äë5 (No OCR)

A tiny Streamlit web app that transcribes text from images using OpenAI‚Äôs GPT‚Äë5 (with an optional Code Interpreter tool). It does not use OCR libraries‚Äîthe model looks at the pixels.
	‚Ä¢	Upload images or PDFs
	‚Ä¢	Sends one image/page per request
	‚Ä¢	Runs requests in parallel for speed
	‚Ä¢	Drag the file names to reorder; previews and final transcript follow that order
	‚Ä¢	Reset/Clear button to start fresh
	‚Ä¢	Code Interpreter toggle (on/off). If off, the prompt line about using it is removed and the tool isn‚Äôt sent.

‚∏ª

Demo

(Optional) Add a short GIF or screenshot here showing: upload ‚Üí drag names ‚Üí transcribe ‚Üí combined result.

‚∏ª

Features
	‚Ä¢	Multiple file types: PNG, JPG/JPEG, WEBP, TIFF, BMP, GIF, and PDF
	‚Ä¢	PDFs are split into pages (rendered via PyMuPDF) and processed page‚Äëby‚Äëpage
	‚Ä¢	Multi‚Äëframe images (e.g., animated GIF/TIFF) use the first frame
	‚Ä¢	Drag‚Äëand‚Äëdrop ordering (names): Uses streamlit-sortables.
	‚Ä¢	After you drag names, the image previews rearrange to match
	‚Ä¢	The combined transcript respects the shown order
	‚Ä¢	Parallel requests: Adjustable concurrency to balance speed vs. rate limits
	‚Ä¢	No OCR: No OCR libraries are installed or used
	‚Ä¢	Mac‚Äëfriendly: Simple Python deps; works great on macOS (also fine on Linux/Windows)

‚∏ª

Requirements
	‚Ä¢	Python 3.9+
	‚Ä¢	An OpenAI API key with access to a GPT‚Äë5 vision‚Äëcapable model
You can change the model in the app‚Äôs sidebar if needed.

‚∏ª

Quickstart

# 1) Create & activate a virtualenv
python -m venv .venv
source .venv/bin/activate  # macOS/Linux
# .venv\Scripts\activate   # Windows PowerShell

# 2) Install deps
pip install -r requirements.txt

# 3) Set your API key
cp .env.example .env
# then edit .env and paste your real key (OPENAI_API_KEY=sk-...)

# 4) Run the app
streamlit run app.py

Open the local URL Streamlit prints (usually http://localhost:8501).

‚∏ª

Usage
	1.	Upload images and/or a PDF.
	2.	(Optional) Drag the file names to set the order.
	‚Ä¢	PDFs keep their original page order (reordering disabled).
	‚Ä¢	After dropping, the preview grid will reflect your chosen order.
	3.	(Optional) In the sidebar, adjust:
	‚Ä¢	Parallel requests (concurrency)
	‚Ä¢	PDF render DPI (higher = crisper pages, slower)
	‚Ä¢	Code Interpreter (on/off)
	‚Ä¢	Model (defaults to gpt-5)
	4.	Click Transcribe with GPT‚Äë5.
	5.	Review per‚Äëimage results, then copy or download the combined transcript as a .txt.

Use üîÅ Reset / Clear files (sidebar) to start over.

‚∏ª

How it works (high level)
	‚Ä¢	Each image or PDF page is converted to PNG bytes (for PDFs, via PyMuPDF at your chosen DPI).
	‚Ä¢	The app sends exactly one input_image per request to the OpenAI Responses API using the selected model.
	‚Ä¢	Requests are concurrent (configurable concurrency).
	‚Ä¢	The system prompt forces ‚Äútranscription only‚Äù. If Code Interpreter is on, the tool is attached‚Ä¶
	‚Ä¢	‚Ä¶and the instructions include: ‚ÄúYou may use the code interpreter to crop, rotate, zoom‚Ä¶ but not OCR.‚Äù
	‚Ä¢	If the toggle is off, that line is omitted and the tool is not sent.
	‚Ä¢	The individual transcripts are joined (in order) into one final output.

‚∏ª

Project structure

.
‚îú‚îÄ app.py                 # Streamlit app
‚îú‚îÄ requirements.txt       # Minimal, Mac-friendly deps
‚îî‚îÄ .env.example           # Template for OPENAI_API_KEY


‚∏ª

Configuration
	‚Ä¢	OPENAI_API_KEY: set in .env
	‚Ä¢	Model: change in the sidebar (default gpt-5)
	‚Ä¢	Parallel requests: sidebar slider (1‚Äì8)
	‚Ä¢	PDF DPI: sidebar slider (120‚Äì300). Higher = sharper render (better transcription), but slower.

‚∏ª

Supported inputs
	‚Ä¢	Images: png, jpg, jpeg, webp, tif, tiff, bmp, gif
	‚Ä¢	Animated images use the first frame
	‚Ä¢	PDF: split into pages (in document order)

HEIC isn‚Äôt included by default. If you need iPhone HEIC support, you can add pillow-heif and register it‚Äîping me and I‚Äôll show you how.

‚∏ª

Limits & notes
	‚Ä¢	No OCR libraries are used. The model reads pixels; for tiny/blurred text, results may vary.
	‚Ä¢	Rate limits: If you hit 429s, lower Parallel requests.
	‚Ä¢	Costs: Each page/image is a separate request‚Äîkeep an eye on token & image usage.
	‚Ä¢	Privacy: Files are sent to OpenAI to generate transcripts; nothing is stored by this app.

‚∏ª

Troubleshooting
	‚Ä¢	Nothing happens / button disabled ‚Üí Ensure your API key is set (sidebar or .env).
	‚Ä¢	‚ÄúModule not found‚Äù for PyMuPDF ‚Üí Reinstall deps: pip install -r requirements.txt.
	‚Ä¢	PDF pages look blurry ‚Üí Increase PDF render DPI (try 220‚Äì260).
	‚Ä¢	429 / rate limit ‚Üí Lower concurrency; try 2 or 3.
	‚Ä¢	Mixed order after dragging ‚Üí The preview grid should mirror the name list after the app reruns. If not, use Reset and try again.

‚∏ª

Extending (optional ideas)
	‚Ä¢	Add HEIC support via pillow-heif.
	‚Ä¢	Export to .md with simple heading detection (still no OCR).
	‚Ä¢	Optional ‚ÄúUnlock PDF order‚Äù to manually reorder pages.
	‚Ä¢	Persist session state across refreshes.

‚∏ª

Security & privacy
	‚Ä¢	Your API key stays local (loaded from .env or sidebar).
	‚Ä¢	The app sends your uploaded files to OpenAI only to get transcriptions.
	‚Ä¢	No third‚Äëparty OCR or cloud storage is used.

‚∏ª

License

Choose a license that fits your needs (MIT is a common choice). If you want, I‚Äôll add an MIT LICENSE file.

‚∏ª

Credits
	‚Ä¢	Built with Streamlit, Pillow, PyMuPDF, and the OpenAI Python SDK (Responses API).
	‚Ä¢	Drag‚Äëand‚Äëdrop ordering powered by streamlit‚Äësortables.

‚∏ª